{
  "latex_resume_code": "\\documentclass[a4paper,12pt]{article}\n\n\\usepackage{mathptmx}\n\\usepackage{url}\n\\usepackage{parskip}\n\\RequirePackage{color}\n\\RequirePackage{graphicx}\n\\usepackage[usenames,dvipsnames]{xcolor}\n\\usepackage[top=0.2in, bottom=0.3in, left=0.3in, right=0.3in]{geometry}\n\\usepackage{tabularx}\n\\usepackage{enumitem}\n\\usepackage{supertabular}\n\\usepackage{titlesec}\n\\usepackage{multicol}\n\\usepackage{multirow}\n\\usepackage{fontawesome5}\n\n\\newcolumntype{C}{>{\\centering\\arraybackslash}X}\n\n\\titleformat{\\section}{\\Large\\scshape\\raggedright}{}{0em}{}[\\titlerule]\n\\titlespacing{\\section}{0pt}{5pt}{5pt}\n\n\\usepackage[unicode, draft=false]{hyperref}\n\\definecolor{linkcolour}{rgb}{0,0.2,0.6}\n\\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour,linkcolor=linkcolour}\n\n% Custom Environments\n\\newenvironment{jobshort}[2]\n    {\n    \\begin{tabularx}{\\linewidth}{@{}l X r@{}}\n    \\textbf{#1} & \\hfill &  #2 \\\\\\\\[2pt]\n    \\end{tabularx}\n    }\n    {}\n\n\\newenvironment{joblong}[2]\n    {\n    \\begin{tabularx}{\\linewidth}{@{}X r@{}}\n    \\textbf{#1} & #2 \\\\\\\\[2pt]\n    \\end{tabularx}\n    \\begin{minipage}[t]{\\linewidth}\n    \\begin{itemize}[nosep,after=\\strut, leftmargin=1em, itemsep=1pt,label=--]\n    }\n    {\n    \\end{itemize}\n    \\end{minipage}\n    }\n\n\\begin{document}\n\\pagestyle{empty}\n\n% HEADER\n\\begin{tabularx}{\\linewidth}{@{} C @{}}\n\\Huge{Gyan Prakash Kushwaha} \\\\\\\\[5pt]\n\\href{https://github.com/gyanprakashkushwaha}{\\faGithub\\ GitHub} \\ $|$ \\\n\\href{https://www.linkedin.com/in/gyanprakashkushwaha}{\\faLinkedin\\ LinkedIn} \\ $|$ \\\n\\href{mailto:gyanprakash.sde@gmail.com}{\\faEnvelope \\ gyanprakash.sde} \\ $|$ \\\n\\href{tel:+919575765381}{\\faMobile \\ +91 9575765381} \\\\\\\\\n\\end{tabularx}\n\n% SUMMARY\n\\section{Summary}\nHighly analytical and problem-solving AI Engineering Undergraduate from IIT Madras, adept at building agentic RAG workflows and end-to-end ML systems using LangGraph, FastAPI, and Vector DBs. Possessing strong DSA fundamentals (219+ LeetCode problems), proficient in reducing inference latency and deploying scalable AI solutions. Eager to apply Generative AI and backend optimization skills in an SDE/AI internship, leveraging experience in simplifying complex AI concepts and mentoring peers, as demonstrated through project leadership and clear technical communication.\n\n% EDUCATION\n\\section{Education}\n\\begin{tabularx}{\\linewidth}{@{}X r@{}}\n\\textbf{Indian Institute of Technology (IIT), Madras} & Chennai, Tamil Nadu \\\\\\\\\n\\textit{BS in Data Science and Applications; CGPA: 8.18/10} & \\textit{2023 -- 2027} \\\\\\\\\n\\end{tabularx}\n\n% SKILLS\n\\section{Skills}\n\\begin{tabularx}{\\linewidth}{@{}l X@{}}\n\\textbf{Programming Languages} & \\normalsize{Python, JavaScript (ES6+), Java, SQL} \\\\\\\\\n\\textbf{Backend Frameworks} & \\normalsize{Flask, FastAPI, Node.js} \\\\\\\\\n\\textbf{Frontend Technologies} & \\normalsize{React, Vue.js, Bootstrap, Tailwind CSS} \\\\\\\\\n\\textbf{Databases \\& Storage Systems} & \\normalsize{PostgreSQL, SQLite, DuckDB, Redis} \\\\\\\\\n\\textbf{Vector Databases \\& Search} & \\normalsize{FAISS, ChromaDB} \\\\\\\\\n\\textbf{Machine Learning \\& NLP} & \\normalsize{NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow, NLTK} \\\\\\\\\n\\textbf{Data Visualization} & \\normalsize{Power BI, Matplotlib, Seaborn, Plotly} \\\\\\\\\n\\textbf{Generative AI \\& LLM Frameworks} & \\normalsize{LangChain, LangGraph, LangSmith, AGNO, Gemini (Flash-Lite, 1.5 Pro), OpenAI (GPT-3/4), LLaMA, Mistral, Fine-tuning (PEFT, LoRA)} \\\\\\\\\n\\textbf{DevOps \\& Systems} & \\normalsize{Linux, Git, GitHub, Celery} \\\\\\\\\n\\textbf{Cloud Platforms} & \\normalsize{AWS (EC2, S3, Lambda), GCP} \\\\\\\\\n\\end{tabularx}\n\n% PROJECTS\n\\section{Projects}\n\n\\begin{joblong}{YouTube RAG Chatbot \\textmd{$|$ LangGraph, FastAPI, FAISS, AsyncSQLite, Vue.js, Gemini (Flash-Lite)}}{\\href{https://github.com/gyanprakashkushwaha/youtube-rag-chatbot}{Repo Link}}\n\\item Reduced Time-to-First-Token (TTFT) by 90\\% (from 5s to $<$500ms) by engineering a real-time async streaming pipeline with FastAPI and LangGraph, significantly improving user perceived responsiveness.\n\\item Architected a stateful RAG workflow using LangGraph and AsyncSQLite to orchestrate persistent, multi-turn conversations, enabling context coherence across 1-hour+ video transcripts.\n\\item Increased RAG response accuracy by implementing Maximal Marginal Relevance (MMR) search, filtering 90\\% of redundant context from long-form audio transcripts to minimize LLM hallucinations.\n\\end{joblong}\n\n\\begin{joblong}{CropGuardian-AI \\textmd{$|$ LangGraph, FastAPI, Pydantic, Gemini 1.5 Pro, OpenMeteo}}{\\href{https://github.com/gyanprakashkushwaha/cropguardian-ai}{Repo Link}}\n\\item Architected a multi-agent workflow using LangGraph to orchestrate 3 specialized agents (Vision, Weather, Agronomy), automating the complex reasoning chain from image analysis to actionable advice with $<$3s latency.\n\\item Implemented strict Structured Output enforcement using Pydantic and Gemini 1.5 Pro, achieving 100\\% schema compliance for JSON responses and eliminating parsing errors in the frontend application.\n\\item Designed a context-aware reasoning engine that grounds visual diagnosis in real-time environmental data (OpenMeteo API), generating location-specific farming action plans based on 7-day weather forecasts.\n\\end{joblong}\n\n\\begin{joblong}{Customer Churn Predictor \\textmd{$|$ Python, Scikit-learn, XGBoost, MLflow, Streamlit}}{\\href{https://github.com/gyanprakashkushwaha/customer-churn-predictor}{Repo Link}}\n\\item Developed a modular machine learning pipeline to process 100,000 customer records, benchmarking performance across 4 ensemble algorithms (XGBoost, Random Forest, AdaBoost, Gradient Boosting) to identify optimal churn predictors and optimize model performance for actionable insights.\n\\item Engineered a robust training workflow integrated with MLflow to systematically track model metrics, parameters, and version history, ensuring reproducibility across experimentation cycles.\n\\item Deployed the best-performing model as an interactive web application using Streamlit, facilitating understanding for non-technical stakeholders to input customer demographics and generate real-time churn risk assessments, effectively bridging technical insights with business needs.\n\\end{joblong}\n\n\\begin{joblong}{Movie Recommender System \\textmd{$|$ Python, Scikit-Learn, Streamlit, Pandas}}{\\href{https://github.com/gyanprakashkushwaha/movie-recommender-system}{Repo Link}}\n\\item Developed a Content-Based Movie Recommender System using Python and Streamlit, processing a dataset of 4,800+ movies to generate highly personalized top-10 viewing suggestions, enhancing user engagement.\n\\item Engineered a feature extraction pipeline with Pandas and Scikit-Learn, transforming unstructured metadata (genres, cast, crew) into a 5,000-feature Bag-of-Words model to calculate Cosine Similarity scores.\n\\item Deployed an interactive web application integrating the TMDB API to fetch real-time posters, utilizing Pickle serialization to optimize data loading and deliver recommendations efficiently.\n\\end{joblong}\n\n% ACHIEVEMENTS\n\\section{Achievements}\n\\begin{itemize}[leftmargin=*]\n  \\item \\textbf{Kaggle Expert}: Top 4\\% globally (Rank 341), 1 Silver \\& 9 Bronze medals; datasets with 22K+ views and 5.6K+ downloads\n  \\item \\textbf{LeetCode}: Solved 219+ DSA problems (100+ Medium)\n  \\item \\textbf{HackerRank}: 5$\\star$Gold Badge (SQL)\n\\end{itemize}\n\n\\end{document}"
}
