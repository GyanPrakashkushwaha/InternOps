{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6466b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GyanPrakashKuswaha\\GenAI\\InternOps\n",
      "d:\\GyanPrakashKuswaha\\GenAI\\InternOps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(r\"d:\\GyanPrakashKuswaha\\GenAI\\InternOps\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5942d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78e752c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\n",
    "    file_path=\"jd_and_resume/resume.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f42f7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f659418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gyan Prakash Kushwaha\n",
      "/githubGitHub| /linkedinLinkedIn| /gl⌢beKaggle| /envel⌢pegyanprakash.sde| ♂¶obile+91 9575765381\n",
      "SUMMARY\n",
      "AI Engineering Undergraduate (IIT Madras) with strong DSA fundamentals (200+ LeetCodeproblems). Experi-\n",
      "enced in buildingagentic RAG workflowsand end-to-end ML systems usingLangGraph, FastAPI, and Vector\n",
      "DBs. Proficient in reducing inference latency and deploying scalable AI solutions. Seeking an SDE/AI internship to\n",
      "leverage skills in Generative AI and backend optimization.\n",
      "EDUCATION\n",
      "Indian Institute of Technology (IIT), MadrasChennai, Tamil Nadu\n",
      "BS in Data Science and Applications; CGPA: 8.18/10 2023 – 2027\n",
      "SKILLS\n",
      "Programming Languages Python, JavaScript (ES6+), Java, SQL\n",
      "Backend Frameworks Flask, FastAPI, Node.js\n",
      "Frontend Technologies React, Vue.js, Bootstrap, Tailwind CSS\n",
      "Databases & Storage Systems PostgreSQL, SQLite, DuckDB, Redis\n",
      "Vector Databases & Search FAISS, ChromaDB\n",
      "Machine Learning & NLP NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow, NLTK\n",
      "Data Visualization Power BI, Matplotlib, Seaborn, Plotly\n",
      "Generative AI & LLM Frameworks LangChain, LangGraph, LangSmith, AGNO\n",
      "DevOps & Systems Linux, Git, GitHub, Celery\n",
      "Cloud Platforms AWS (EC2, S3, Lambda), GCP\n",
      "PROJECTS\n",
      "YouTube RAG Chatbot|LangGraph, FastAPI, FAISS, AsyncSQLite, Vue.js, Gemini (Flash-Lite) Repo Link\n",
      "– ReducedTime-to-First-Token (TTFT) by 90%(from 5s to<500ms) by engineering a real-time async streaming\n",
      "pipeline withFastAPIandLangGraph, significantly improving user perceived responsiveness.\n",
      "– Architected astateful RAG workflowusingLangGraphandAsyncSQLiteto orchestrate persistent, multi-turn\n",
      "conversations, enabling context coherence across1-hour+ video transcripts.\n",
      "– Increased RAG response accuracy by implementingMaximal Marginal Relevance (MMR)search, filtering\n",
      "90% of redundant contextfrom long-form audio transcripts to minimizeLLM hallucinations.\n",
      "CropGuardian-AI|LangGraph, FastAPI, Pydantic, Gemini 1.5 Pro, OpenMeteo Repo Link\n",
      "– Architected amulti-agent workflowusingLangGraphto orchestrate3 specialized agents(Vision, Weather,\n",
      "Agronomy), automating the complex reasoning chain from image analysis to actionable advice with<3s latency.\n",
      "– Implemented strictStructured Outputenforcement usingPydanticandGemini 1.5 Pro, achieving100%\n",
      "schema compliancefor JSON responses and eliminating parsing errors in the frontend application.\n",
      "– Designed acontext-aware reasoning enginethat grounds visual diagnosis in real-time environmental data\n",
      "(OpenMeteo API), generating location-specific farming action plans based on7-day weather forecasts.\n",
      "Customer Churn Predictor|Python, Scikit-learn, XGBoost, MLflow, Streamlit Repo Link\n",
      "– Developed a modular machine learning pipeline to process100,000 customer records, benchmarking perfor-\n",
      "mance across4 ensemble algorithms(XGBoost, Random Forest, AdaBoost, Gradient Boosting) to identify op-\n",
      "timal churn predictors.\n",
      "– Engineered a robust training workflow integrated withMLflowto systematically track model metrics, parameters,\n",
      "and version history, ensuringreproducibilityacross experimentation cycles.\n",
      "– Deployed the best-performing model as an interactive web application usingStreamlit, enabling non-technical\n",
      "stakeholders to input customer demographics and generatereal-time churn risk assessments.\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cb2b833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "211489e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Recommender System|Python, Scikit-Learn, Streamlit, Pandas Repo Link\n",
      "–Developed a Content-Based Movie Recommender SystemusingPythonandStreamlit, processing a dataset\n",
      "of4,800+ moviesto generate personalized top-10 viewing suggestions.\n",
      "–Engineered a feature extraction pipelinewithPandasandScikit-Learn, transforming unstructured metadata\n",
      "(genres, cast, crew) into a5,000-featureBag-of-Words model to calculateCosine Similarityscores.\n",
      "–Deployed an interactive web applicationintegrating theTMDB APIto fetch real-time posters, utilizingPickle\n",
      "serialization to optimize data loading and deliver recommendations efficiently.\n",
      "ACHIEVEMENTS\n",
      "•Kaggle Expert: Top 4% globally (Rank 341), 1 Silver & 9 Bronze medals; datasets with 22K+ views and 5.6K+\n",
      "downloads\n",
      "•LeetCode: Solved 219+ DSA problems (100+ Medium)\n",
      "•HackerRank: 5⋆Gold Badge (SQL)\n"
     ]
    }
   ],
   "source": [
    "print(doc[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e104b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gyan Prakash Kushwaha\n",
      "/githubGitHub| /linkedinLinkedIn| /gl⌢beKaggle| /envel⌢pegyanprakash.sde| ♂¶obile+91 9575765381\n",
      "SUMMARY\n",
      "AI Engineering Undergraduate (IIT Madras) with strong DSA fundamentals (200+ LeetCodeproblems). Experi-\n",
      "enced in buildingagentic RAG workflowsand end-to-end ML systems usingLangGraph, FastAPI, and Vector\n",
      "DBs. Proficient in reducing inference latency and deploying scalable AI solutions. Seeking an SDE/AI internship to\n",
      "leverage skills in Generative AI and backend optimization.\n",
      "EDUCATION\n",
      "Indian Institute of Technology (IIT), MadrasChennai, Tamil Nadu\n",
      "BS in Data Science and Applications; CGPA: 8.18/10 2023 – 2027\n",
      "SKILLS\n",
      "Programming Languages Python, JavaScript (ES6+), Java, SQL\n",
      "Backend Frameworks Flask, FastAPI, Node.js\n",
      "Frontend Technologies React, Vue.js, Bootstrap, Tailwind CSS\n",
      "Databases & Storage Systems PostgreSQL, SQLite, DuckDB, Redis\n",
      "Vector Databases & Search FAISS, ChromaDB\n",
      "Machine Learning & NLP NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow, NLTK\n",
      "Data Visualization Power BI, Matplotlib, Seaborn, Plotly\n",
      "Generative AI & LLM Frameworks LangChain, LangGraph, LangSmith, AGNO\n",
      "DevOps & Systems Linux, Git, GitHub, Celery\n",
      "Cloud Platforms AWS (EC2, S3, Lambda), GCP\n",
      "PROJECTS\n",
      "YouTube RAG Chatbot|LangGraph, FastAPI, FAISS, AsyncSQLite, Vue.js, Gemini (Flash-Lite) Repo Link\n",
      "– ReducedTime-to-First-Token (TTFT) by 90%(from 5s to<500ms) by engineering a real-time async streaming\n",
      "pipeline withFastAPIandLangGraph, significantly improving user perceived responsiveness.\n",
      "– Architected astateful RAG workflowusingLangGraphandAsyncSQLiteto orchestrate persistent, multi-turn\n",
      "conversations, enabling context coherence across1-hour+ video transcripts.\n",
      "– Increased RAG response accuracy by implementingMaximal Marginal Relevance (MMR)search, filtering\n",
      "90% of redundant contextfrom long-form audio transcripts to minimizeLLM hallucinations.\n",
      "CropGuardian-AI|LangGraph, FastAPI, Pydantic, Gemini 1.5 Pro, OpenMeteo Repo Link\n",
      "– Architected amulti-agent workflowusingLangGraphto orchestrate3 specialized agents(Vision, Weather,\n",
      "Agronomy), automating the complex reasoning chain from image analysis to actionable advice with<3s latency.\n",
      "– Implemented strictStructured Outputenforcement usingPydanticandGemini 1.5 Pro, achieving100%\n",
      "schema compliancefor JSON responses and eliminating parsing errors in the frontend application.\n",
      "– Designed acontext-aware reasoning enginethat grounds visual diagnosis in real-time environmental data\n",
      "(OpenMeteo API), generating location-specific farming action plans based on7-day weather forecasts.\n",
      "Customer Churn Predictor|Python, Scikit-learn, XGBoost, MLflow, Streamlit Repo Link\n",
      "– Developed a modular machine learning pipeline to process100,000 customer records, benchmarking perfor-\n",
      "mance across4 ensemble algorithms(XGBoost, Random Forest, AdaBoost, Gradient Boosting) to identify op-\n",
      "timal churn predictors.\n",
      "– Engineered a robust training workflow integrated withMLflowto systematically track model metrics, parameters,\n",
      "and version history, ensuringreproducibilityacross experimentation cycles.\n",
      "– Deployed the best-performing model as an interactive web application usingStreamlit, enabling non-technical\n",
      "stakeholders to input customer demographics and generatereal-time churn risk assessments.\n",
      "Movie Recommender System|Python, Scikit-Learn, Streamlit, Pandas Repo Link\n",
      "–Developed a Content-Based Movie Recommender SystemusingPythonandStreamlit, processing a dataset\n",
      "of4,800+ moviesto generate personalized top-10 viewing suggestions.\n",
      "–Engineered a feature extraction pipelinewithPandasandScikit-Learn, transforming unstructured metadata\n",
      "(genres, cast, crew) into a5,000-featureBag-of-Words model to calculateCosine Similarityscores.\n",
      "–Deployed an interactive web applicationintegrating theTMDB APIto fetch real-time posters, utilizingPickle\n",
      "serialization to optimize data loading and deliver recommendations efficiently.\n",
      "ACHIEVEMENTS\n",
      "•Kaggle Expert: Top 4% globally (Rank 341), 1 Silver & 9 Bronze medals; datasets with 22K+ views and 5.6K+\n",
      "downloads\n",
      "•LeetCode: Solved 219+ DSA problems (100+ Medium)\n",
      "•HackerRank: 5⋆Gold Badge (SQL)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resume_text = \"\"\"\"\"\"\n",
    "\n",
    "for page in doc:\n",
    "    resume_text += page.page_content + \"\\n\"\n",
    "\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce88aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"jd_and_resume/jd.txt\", encoding=\"utf-8\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67f00233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Description\n",
      "Job Title: Data Science & AI Intern  \n",
      "\n",
      "Company: GEODISHA \n",
      "\n",
      "Location: Hyderabad - Onsite \n",
      "\n",
      "Duration: 1- 4 Months \n",
      "\n",
      "About GEODISHA \n",
      "\n",
      "At GEODISHA, we are at the forefront of Data Analytics and AI, leveraging data to solve  complex problems and drive innovation. Our team is a dedicated group of researchers, engineers,  and strategists who believe in the power of technology. We are passionately committed to  developing cutting-edge AI that is not only powerful but also ethical, transparent, and fair. We're  looking for the next generation of innovators to join us. \n",
      "\n",
      "The Opportunity: This Isn't Your Typical Internship \n",
      "\n",
      "We are seeking truly exceptional interns to join our core Data & AI team. This is a unique  opportunity to move beyond theory and apply your skills to high-impact, real-world challenges  across the full data lifecycle. \n",
      "\n",
      "You won't be on the sidelines. You'll be paired with a senior mentor and embedded directly into  projects at the intersection of data engineering, data analytics, artificial intelligence, and human  behavior. We are looking for a candidate who is not just an outstanding programmer, but a  critical thinker who understands that great AI starts with great data, is passionate about the  \"why\" behind the data, and sees the critical importance of building Responsible AI. \n",
      "\n",
      "What You’ll Do (Key Responsibilities): \n",
      "\n",
      "∉ Assist in developing AI-driven recommendation engines and personalization workflows. ∉ Analyze structured and unstructured datasets to derive insights and patterns. ∉ Work with senior team members on customer segmentation, predictive modeling, and LLM integrated analytics tools. \n",
      "\n",
      "∉ Learn and support the development of modular data pipelines and models using industry  tools. \n",
      "\n",
      "∉ Use Python, SQL, scikit-learn, and other libraries for experimentation and development. ∉ Present findings through visualization tools such as seaborn, matplotlib, or BI tools like  Power BI. \n",
      "\n",
      "∉ Document code, experiments, and insights for further development. \n",
      "\n",
      "Who You Are (Our Ideal Candidate):\n",
      "\n",
      "We are looking for a rising star who is driven, curious, and eager to make a tangible impact. \n",
      "\n",
      "Core Requirements: \n",
      "\n",
      "∉ Currently pursuing or recently completed a degree in Data Science, Computer Science,  Statistics, Mathematics, or related field. \n",
      "\n",
      "∉ Good understanding of Python and SQL (R is a plus). \n",
      "\n",
      "∉ Familiarity with basic ML algorithms: classification, regression, clustering. ∉ Exposure to libraries such as pandas, NumPy, scikit-learn, etc. \n",
      "\n",
      "∉ Interest in GenAI/NLP concepts like transformers or LLMs is a bonus. ∉ Strong analytical mindset, curiosity, and willingness to learn. \n",
      "\n",
      "Passion & Interest (What Sets You Apart): \n",
      "\n",
      "∉ A genuine and demonstrable passion for the entire Data Analytics space, from robust  engineering to insightful analysis. \n",
      "\n",
      "∉ Academic or project-based exposure to Behavioral Analytics or computational social  science. \n",
      "\n",
      "∉ A strong, well-articulated interest in the field of Responsible AI, ethics, and algorithmic  fairness \n",
      "\n",
      "Bonus Points: \n",
      "\n",
      "∉ Exposure to tools like TensorFlow, Hugging Face, or BI dashboards. \n",
      "\n",
      "∉ Basic understanding of cloud platforms (AWS/GCP/Azure), Git, or APIs. ∉ Academic projects, personal experiments, or GitHub repositories demonstrating interest in  AI/ML. \n",
      "\n",
      "What You’ll Gain: \n",
      "\n",
      "● Hands-on experience in a startup environment working on cutting-edge AdTech & MarTech  products. \n",
      "\n",
      "● Mentorship from senior Data Science and AI professionals. \n",
      "\n",
      "● A chance to convert the internship into a full-time position based on performance.\n",
      "\n",
      "Type of Opportunity: Internship \n",
      "\n",
      "Job Title: Data Science & AI Intern\n",
      "\n",
      "       \n",
      "\n",
      "Selection Process: Technical Interview + Personal Interview\n",
      "\n",
      "Monthly Stipend / Annual CTC: INR 25,000 - 30,000 / month\n",
      "\n",
      "Internship Duration: 1 - 4 months\n",
      "\n",
      "Proposed Start Date: December 1, 2025\n",
      "\n",
      "Work Hours: 11:00 AM - 8:00 PM\n",
      "\n",
      "Mode of Work: In-person \n",
      "\n",
      "Primary Work Location: Hyderabad\n",
      "\n",
      "Immediate Joining Requirement: Yes \n",
      "\n",
      "Head Office Location: Hyderabad\n",
      "\n",
      "Number of Open Positions: 2 \n",
      "\n",
      "Please Note :\n",
      "\n",
      "The last date to apply for this opportunity is November 18, 2025 by 11 AM IST.\n",
      "Not adhering to placement and internship policy rules will lead to necessary disciplinary actions by the committee.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jd = \"\"\"\"\"\"\n",
    "for doc in document:\n",
    "    jd += doc.page_content + \"\\n\"\n",
    "\n",
    "print(jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c154fca",
   "metadata": {},
   "source": [
    "## LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cef356a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Literal, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5df1062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillGap(BaseModel):\n",
    "    skill_name: str = Field(..., description=\"The specific skill missing.\")\n",
    "    priority: Literal['High', 'Medium', 'Low'] = Field(..., description=\"High if required by JD, Medium if preferred.\")\n",
    "    learning_difficulty: Literal['Hard', 'Moderate', 'Easy'] = Field(..., description=\"Hard (Needs months), Moderate (Weeks), Easy (Hours).\")\n",
    "\n",
    "class CareerAdvice(BaseModel):\n",
    "    match_percentage: int = Field(..., description=\"0-100 score.\")\n",
    "    fit_category: Literal[\"Perfect Match\", \"Good Match\", \"Hard Reach\"] = Field(..., description=\"The classification of the candidate.\")\n",
    "    \n",
    "    # The 'Voice' of the assistant\n",
    "    verdict_message: str = Field(..., description=\"A direct message to the intern. E.g., 'Hey, this isn't for you yet' or 'You are almost there!'.\")\n",
    "    \n",
    "    missing_skills: List[SkillGap] = Field(..., description=\"List of gaps.\")\n",
    "    \n",
    "    # Specific logic for time\n",
    "    estimated_preparation_time: str = Field(..., description=\"E.g., '2 hours', '1 weekend', '2 months'. Based on the difficulty of missing skills.\")\n",
    "    \n",
    "    action_plan: List[str] = Field(..., description=\"Bulleted list of exactly what to study or fix in the resume.\")\n",
    "\n",
    "# Initialize Model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "extractor_llm = model.with_structured_output(CareerAdvice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "123e74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "class ResumeState(TypedDict):\n",
    "    resume: str\n",
    "    jd: str\n",
    "    result: CareerAdvice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e959dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(state: ResumeState):\n",
    "    # --- UNIVERSAL STRICT GATEKEEPER PROMPT ---\n",
    "    sys_message = SystemMessage(content=\"\"\"\n",
    "        You are a **Brutal AI Recruiter & Gatekeeper**. \n",
    "        Your specific goal is to **protect candidates from rejection** by stopping them from applying to roles where they have NO chance.\n",
    "\n",
    "        **YOUR JOB:**\n",
    "        Compare the RESUME against the JOB DESCRIPTION (JD) objectively.\n",
    "\n",
    "        **SCORING & DECISION LOGIC:**\n",
    "\n",
    "        **1. THE \"HARD STOP\" (Score < 50):**\n",
    "           * **Trigger:** The candidate fails **Mandatory Requirements** (Deal Breakers).\n",
    "             * Examples of Deal Breakers:\n",
    "               * JD requires 5+ years experience, Candidate has 0-1.\n",
    "               * JD requires specific Core Tech (e.g., \"Must know Java/Spring\"), Candidate only knows \"Python/Django\".\n",
    "               * JD requires specific Domain (e.g., \"Must have Finance background\"), Candidate has none.\n",
    "           * **Verdict Message:** \"STOP. Do not apply. You fail the mandatory 'Hard Requirements' for this specific role. You will be auto-rejected.\"\n",
    "           * **Action Plan:** Do NOT give a study plan. Return a single bullet point: \"Look for roles that match your current [Experience Level / Tech Stack] instead.\"\n",
    "           * **Fit Category:** \"Hard Reach\"\n",
    "\n",
    "        **2. THE \"RISKY BET\" (Score 50-79):**\n",
    "           * **Trigger:** Candidate matches the core profile (e.g., correct years of experience, correct main language) but misses specific tools, libraries, or \"Preferred\" skills.\n",
    "           * **Verdict Message:** \"You are a partial match. You might get an interview, but you are at a disadvantage compared to perfect fits.\"\n",
    "           * **Action Plan:** specific list of tools/concepts to learn quickly (e.g., \"Learn Docker\", \"Build a project with LangChain\").\n",
    "           * **Fit Category:** \"Good Match\"\n",
    "\n",
    "        **3. THE \"STRONG FIT\" (Score 80-100):**\n",
    "           * **Trigger:** Candidate matches all Hard Requirements and most Preferred Requirements.\n",
    "           * **Verdict Message:** \"You are a strong candidate. Apply immediately.\"\n",
    "           * **Action Plan:** Minor Resume polishing suggestions.\n",
    "           * **Fit Category:** \"Perfect Match\"\n",
    "\n",
    "        **IMPORTANT:**\n",
    "        * Be purely objective. \n",
    "        * Do not hallucinate skills. \n",
    "        * If the JD is very specific (e.g., \"Must be located in Berlin\"), check if the resume mentions location.\n",
    "    \"\"\")\n",
    "    \n",
    "    human_message = HumanMessage(content=f\"\"\"\n",
    "        **JOB DESCRIPTION:**\n",
    "        {state['jd']}\n",
    "        \n",
    "        **RESUME:**\n",
    "        {state['resume']}\n",
    "        \n",
    "        Analyze the fit strictly.\n",
    "    \"\"\")\n",
    "    \n",
    "    messages = [sys_message, human_message]\n",
    "    response = extractor_llm.invoke(messages)\n",
    "    \n",
    "    return {\"result\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4422d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "graph = StateGraph(ResumeState)\n",
    "\n",
    "# Nodes\n",
    "graph.add_node(\"llm\", llm)\n",
    "\n",
    "# Edges \n",
    "graph.add_edge(START, \"llm\")\n",
    "graph.add_edge(\"llm\", END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a9000d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001DFD72A9BA0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d68545f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialState = {\n",
    "    \"resume\": resume_text,\n",
    "    \"jd\": jd\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(initialState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b8c9d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resume': 'Gyan Prakash Kushwaha\\n/githubGitHub| /linkedinLinkedIn| /gl⌢beKaggle| /envel⌢pegyanprakash.sde| ♂¶obile+91 9575765381\\nSUMMARY\\nAI Engineering Undergraduate (IIT Madras) with strong DSA fundamentals (200+ LeetCodeproblems). Experi-\\nenced in buildingagentic RAG workflowsand end-to-end ML systems usingLangGraph, FastAPI, and Vector\\nDBs. Proficient in reducing inference latency and deploying scalable AI solutions. Seeking an SDE/AI internship to\\nleverage skills in Generative AI and backend optimization.\\nEDUCATION\\nIndian Institute of Technology (IIT), MadrasChennai, Tamil Nadu\\nBS in Data Science and Applications; CGPA: 8.18/10 2023 – 2027\\nSKILLS\\nProgramming Languages Python, JavaScript (ES6+), Java, SQL\\nBackend Frameworks Flask, FastAPI, Node.js\\nFrontend Technologies React, Vue.js, Bootstrap, Tailwind CSS\\nDatabases & Storage Systems PostgreSQL, SQLite, DuckDB, Redis\\nVector Databases & Search FAISS, ChromaDB\\nMachine Learning & NLP NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow, NLTK\\nData Visualization Power BI, Matplotlib, Seaborn, Plotly\\nGenerative AI & LLM Frameworks LangChain, LangGraph, LangSmith, AGNO\\nDevOps & Systems Linux, Git, GitHub, Celery\\nCloud Platforms AWS (EC2, S3, Lambda), GCP\\nPROJECTS\\nYouTube RAG Chatbot|LangGraph, FastAPI, FAISS, AsyncSQLite, Vue.js, Gemini (Flash-Lite) Repo Link\\n– ReducedTime-to-First-Token (TTFT) by 90%(from 5s to<500ms) by engineering a real-time async streaming\\npipeline withFastAPIandLangGraph, significantly improving user perceived responsiveness.\\n– Architected astateful RAG workflowusingLangGraphandAsyncSQLiteto orchestrate persistent, multi-turn\\nconversations, enabling context coherence across1-hour+ video transcripts.\\n– Increased RAG response accuracy by implementingMaximal Marginal Relevance (MMR)search, filtering\\n90% of redundant contextfrom long-form audio transcripts to minimizeLLM hallucinations.\\nCropGuardian-AI|LangGraph, FastAPI, Pydantic, Gemini 1.5 Pro, OpenMeteo Repo Link\\n– Architected amulti-agent workflowusingLangGraphto orchestrate3 specialized agents(Vision, Weather,\\nAgronomy), automating the complex reasoning chain from image analysis to actionable advice with<3s latency.\\n– Implemented strictStructured Outputenforcement usingPydanticandGemini 1.5 Pro, achieving100%\\nschema compliancefor JSON responses and eliminating parsing errors in the frontend application.\\n– Designed acontext-aware reasoning enginethat grounds visual diagnosis in real-time environmental data\\n(OpenMeteo API), generating location-specific farming action plans based on7-day weather forecasts.\\nCustomer Churn Predictor|Python, Scikit-learn, XGBoost, MLflow, Streamlit Repo Link\\n– Developed a modular machine learning pipeline to process100,000 customer records, benchmarking perfor-\\nmance across4 ensemble algorithms(XGBoost, Random Forest, AdaBoost, Gradient Boosting) to identify op-\\ntimal churn predictors.\\n– Engineered a robust training workflow integrated withMLflowto systematically track model metrics, parameters,\\nand version history, ensuringreproducibilityacross experimentation cycles.\\n– Deployed the best-performing model as an interactive web application usingStreamlit, enabling non-technical\\nstakeholders to input customer demographics and generatereal-time churn risk assessments.\\nMovie Recommender System|Python, Scikit-Learn, Streamlit, Pandas Repo Link\\n–Developed a Content-Based Movie Recommender SystemusingPythonandStreamlit, processing a dataset\\nof4,800+ moviesto generate personalized top-10 viewing suggestions.\\n–Engineered a feature extraction pipelinewithPandasandScikit-Learn, transforming unstructured metadata\\n(genres, cast, crew) into a5,000-featureBag-of-Words model to calculateCosine Similarityscores.\\n–Deployed an interactive web applicationintegrating theTMDB APIto fetch real-time posters, utilizingPickle\\nserialization to optimize data loading and deliver recommendations efficiently.\\nACHIEVEMENTS\\n•Kaggle Expert: Top 4% globally (Rank 341), 1 Silver & 9 Bronze medals; datasets with 22K+ views and 5.6K+\\ndownloads\\n•LeetCode: Solved 219+ DSA problems (100+ Medium)\\n•HackerRank: 5⋆Gold Badge (SQL)\\n', 'jd': 'Job Description\\nJob Title: Data Science & AI Intern  \\n\\nCompany: GEODISHA \\n\\nLocation: Hyderabad - Onsite \\n\\nDuration: 1- 4 Months \\n\\nAbout GEODISHA \\n\\nAt GEODISHA, we are at the forefront of Data Analytics and AI, leveraging data to solve  complex problems and drive innovation. Our team is a dedicated group of researchers, engineers,  and strategists who believe in the power of technology. We are passionately committed to  developing cutting-edge AI that is not only powerful but also ethical, transparent, and fair. We\\'re  looking for the next generation of innovators to join us. \\n\\nThe Opportunity: This Isn\\'t Your Typical Internship \\n\\nWe are seeking truly exceptional interns to join our core Data & AI team. This is a unique  opportunity to move beyond theory and apply your skills to high-impact, real-world challenges  across the full data lifecycle. \\n\\nYou won\\'t be on the sidelines. You\\'ll be paired with a senior mentor and embedded directly into  projects at the intersection of data engineering, data analytics, artificial intelligence, and human  behavior. We are looking for a candidate who is not just an outstanding programmer, but a  critical thinker who understands that great AI starts with great data, is passionate about the  \"why\" behind the data, and sees the critical importance of building Responsible AI. \\n\\nWhat You’ll Do (Key Responsibilities): \\n\\n∉ Assist in developing AI-driven recommendation engines and personalization workflows. ∉ Analyze structured and unstructured datasets to derive insights and patterns. ∉ Work with senior team members on customer segmentation, predictive modeling, and LLM integrated analytics tools. \\n\\n∉ Learn and support the development of modular data pipelines and models using industry  tools. \\n\\n∉ Use Python, SQL, scikit-learn, and other libraries for experimentation and development. ∉ Present findings through visualization tools such as seaborn, matplotlib, or BI tools like  Power BI. \\n\\n∉ Document code, experiments, and insights for further development. \\n\\nWho You Are (Our Ideal Candidate):\\n\\nWe are looking for a rising star who is driven, curious, and eager to make a tangible impact. \\n\\nCore Requirements: \\n\\n∉ Currently pursuing or recently completed a degree in Data Science, Computer Science,  Statistics, Mathematics, or related field. \\n\\n∉ Good understanding of Python and SQL (R is a plus). \\n\\n∉ Familiarity with basic ML algorithms: classification, regression, clustering. ∉ Exposure to libraries such as pandas, NumPy, scikit-learn, etc. \\n\\n∉ Interest in GenAI/NLP concepts like transformers or LLMs is a bonus. ∉ Strong analytical mindset, curiosity, and willingness to learn. \\n\\nPassion & Interest (What Sets You Apart): \\n\\n∉ A genuine and demonstrable passion for the entire Data Analytics space, from robust  engineering to insightful analysis. \\n\\n∉ Academic or project-based exposure to Behavioral Analytics or computational social  science. \\n\\n∉ A strong, well-articulated interest in the field of Responsible AI, ethics, and algorithmic  fairness \\n\\nBonus Points: \\n\\n∉ Exposure to tools like TensorFlow, Hugging Face, or BI dashboards. \\n\\n∉ Basic understanding of cloud platforms (AWS/GCP/Azure), Git, or APIs. ∉ Academic projects, personal experiments, or GitHub repositories demonstrating interest in  AI/ML. \\n\\nWhat You’ll Gain: \\n\\n● Hands-on experience in a startup environment working on cutting-edge AdTech & MarTech  products. \\n\\n● Mentorship from senior Data Science and AI professionals. \\n\\n● A chance to convert the internship into a full-time position based on performance.\\n\\nType of Opportunity: Internship \\n\\nJob Title: Data Science & AI Intern\\n\\n\\u2002\\u2002\\u2002\\u2002\\u2002\\u2002\\u2002\\n\\nSelection Process: Technical Interview + Personal Interview\\n\\nMonthly Stipend / Annual CTC: INR 25,000 - 30,000 / month\\n\\nInternship Duration: 1 - 4 months\\n\\nProposed Start Date: December 1, 2025\\n\\nWork Hours: 11:00 AM - 8:00 PM\\n\\nMode of Work: In-person \\n\\nPrimary Work Location: Hyderabad\\n\\nImmediate Joining Requirement: Yes \\n\\nHead Office Location: Hyderabad\\n\\nNumber of Open Positions: 2 \\n\\nPlease Note :\\n\\nThe last date to apply for this opportunity is November 18, 2025 by 11 AM IST.\\nNot adhering to placement and internship policy rules will lead to necessary disciplinary actions by the committee.\\n', 'result': CareerAdvice(match_percentage=40, fit_category='Hard Reach', verdict_message=\"STOP. Do not apply. You fail the mandatory 'Hard Requirements' for this specific role. You will be auto-rejected.\", missing_skills=[SkillGap(skill_name='Onsite presence in Hyderabad', priority='High', learning_difficulty='Hard'), SkillGap(skill_name='Interest/Experience in Responsible AI, ethics, algorithmic fairness', priority='Medium', learning_difficulty='Moderate'), SkillGap(skill_name='Exposure to Behavioral Analytics or computational social science', priority='Medium', learning_difficulty='Moderate')], estimated_preparation_time='1-3 months (for potential relocation)', action_plan=['Look for roles that match your current location or are explicitly remote/hybrid compatible.'])}\n"
     ]
    }
   ],
   "source": [
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d188ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"result\": final_state[\"result\"].model_dump()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42c6b6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': {'match_percentage': 40,\n",
       "  'fit_category': 'Hard Reach',\n",
       "  'verdict_message': \"STOP. Do not apply. You fail the mandatory 'Hard Requirements' for this specific role. You will be auto-rejected.\",\n",
       "  'missing_skills': [{'skill_name': 'Onsite presence in Hyderabad',\n",
       "    'priority': 'High',\n",
       "    'learning_difficulty': 'Hard'},\n",
       "   {'skill_name': 'Interest/Experience in Responsible AI, ethics, algorithmic fairness',\n",
       "    'priority': 'Medium',\n",
       "    'learning_difficulty': 'Moderate'},\n",
       "   {'skill_name': 'Exposure to Behavioral Analytics or computational social science',\n",
       "    'priority': 'Medium',\n",
       "    'learning_difficulty': 'Moderate'}],\n",
       "  'estimated_preparation_time': '1-3 months (for potential relocation)',\n",
       "  'action_plan': ['Look for roles that match your current location or are explicitly remote/hybrid compatible.']}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
